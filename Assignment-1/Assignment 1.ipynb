{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSc 8830: Computer Vision - Assignment 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the OAK-D camera, set up your application to show a RGB stream from the mono camera and a depth map stream from the stereo camera simultaneously. Make a note of what is the maximum frame rate and resolution achievable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install depthai & opencv-python\n",
    "!pip install depthai opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/606186875.py:27: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  left_camera.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/606186875.py:32: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  right_camera.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 0\n",
      "FPS: 68\n",
      "FPS: 79\n",
      "FPS: 90\n",
      "FPS: 79\n",
      "FPS: 79\n",
      "FPS: 79\n",
      "FPS: 79\n",
      "FPS: 78\n",
      "FPS: 79\n",
      "FPS: 92\n",
      "FPS: 79\n",
      "FPS: 88\n",
      "FPS: 79\n",
      "FPS: 79\n",
      "FPS: 88\n",
      "FPS: 79\n",
      "FPS: 6\n",
      "FPS: 11\n",
      "FPS: 28\n",
      "FPS: 82\n",
      "FPS: 83\n",
      "FPS: 38\n",
      "FPS: 86\n",
      "FPS: 75\n",
      "FPS: 89\n",
      "FPS: 85\n",
      "FPS: 89\n",
      "FPS: 71\n",
      "FPS: 53\n",
      "FPS: 89\n",
      "FPS: 82\n",
      "FPS: 33\n",
      "FPS: 88\n",
      "FPS: 76\n",
      "FPS: 50\n",
      "FPS: 89\n",
      "FPS: 90\n",
      "FPS: 89\n",
      "FPS: 88\n",
      "FPS: 88\n",
      "FPS: 89\n",
      "FPS: 46\n",
      "FPS: 88\n",
      "FPS: 95\n",
      "FPS: 92\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 88\n",
      "FPS: 88\n",
      "FPS: 39\n",
      "FPS: 87\n",
      "FPS: 88\n",
      "FPS: 88\n",
      "FPS: 96\n",
      "FPS: 87\n",
      "FPS: 89\n",
      "FPS: 41\n",
      "FPS: 88\n",
      "FPS: 89\n",
      "FPS: 91\n",
      "FPS: 89\n",
      "FPS: 90\n",
      "FPS: 98\n",
      "FPS: 61\n",
      "FPS: 35\n",
      "FPS: 90\n",
      "FPS: 89\n",
      "FPS: 94\n",
      "FPS: 89\n",
      "FPS: 32\n",
      "FPS: 89\n",
      "FPS: 90\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 58\n",
      "FPS: 32\n",
      "FPS: 86\n",
      "FPS: 86\n",
      "FPS: 88\n",
      "FPS: 87\n",
      "FPS: 87\n",
      "FPS: 42\n",
      "FPS: 89\n",
      "FPS: 86\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 89\n",
      "FPS: 60\n",
      "FPS: 38\n",
      "FPS: 86\n",
      "FPS: 89\n",
      "FPS: 86\n",
      "FPS: 87\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "\n",
    "# Parameters\n",
    "RGB_RESOLUTION = dai.ColorCameraProperties.SensorResolution.THE_1080_P\n",
    "DEPTH_RESOLUTION = dai.MonoCameraProperties.SensorResolution.THE_400_P\n",
    "RESIZE_DIMENSIONS = (720, 480)  \n",
    "EXTENDED_DISPARITY = False  \n",
    "SUBPIXEL_DISPARITY = False  \n",
    "LR_CHECK = True  \n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# RGB Camera configuration\n",
    "rgb_camera = pipeline.create(dai.node.ColorCamera)\n",
    "rgb_camera.setResolution(RGB_RESOLUTION)\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "rgb_camera.video.link(xout_rgb.input)\n",
    "\n",
    "# Left Mono Camera configuration\n",
    "left_camera = pipeline.createMonoCamera()\n",
    "left_camera.setResolution(DEPTH_RESOLUTION)\n",
    "left_camera.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "# Right Mono Camera configuration\n",
    "right_camera = pipeline.createMonoCamera()\n",
    "right_camera.setResolution(DEPTH_RESOLUTION)\n",
    "right_camera.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "# Stereo Depth configuration\n",
    "stereo_depth = pipeline.createStereoDepth()\n",
    "stereo_depth.setExtendedDisparity(EXTENDED_DISPARITY)\n",
    "stereo_depth.setSubpixel(SUBPIXEL_DISPARITY)\n",
    "stereo_depth.setLeftRightCheck(LR_CHECK)\n",
    "left_camera.out.link(stereo_depth.left)\n",
    "right_camera.out.link(stereo_depth.right)\n",
    "\n",
    "# Output queues\n",
    "disparity_output = pipeline.createXLinkOut()\n",
    "disparity_output.setStreamName(\"disparity\")\n",
    "stereo_depth.disparity.link(disparity_output.input)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "prev_frame_time = 0  \n",
    "\n",
    "# Pipeline execution\n",
    "with dai.Device(pipeline) as device:\n",
    "    disparity_queue = device.getOutputQueue(name=\"disparity\", maxSize=4, blocking=False)\n",
    "    rgb_queue = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_frame_time) if prev_frame_time else 0\n",
    "        prev_frame_time = current_time\n",
    "        \n",
    "        # Display RGB frame\n",
    "        if rgb_queue and rgb_queue.has():\n",
    "            rgb_frame = rgb_queue.get()\n",
    "            resized_rgb_frame = cv.resize(rgb_frame.getCvFrame(), RESIZE_DIMENSIONS, interpolation=cv.INTER_AREA)\n",
    "            cv.imshow(\"RGB Frame\", resized_rgb_frame)\n",
    "        \n",
    "        # Display depth map\n",
    "        if disparity_queue and disparity_queue.has():\n",
    "            disparity_frame = disparity_queue.get().getFrame()\n",
    "            if disparity_frame is not None:\n",
    "                # Normalize for better visualization\n",
    "                normalized_disparity = (disparity_frame * (255 / stereo_depth.initialConfig.getMaxDisparity())).astype(np.uint8)\n",
    "                cv.imshow(\"Depth Map\", normalized_disparity)\n",
    "\n",
    "        print(\"FPS:\", int(fps))  # Print FPS in the console\n",
    "        \n",
    "        key = cv.waitKey(1)  # Wait for key press\n",
    "        if key == ord('q'):  # Break the loop if 'q' is pressed\n",
    "            cv.destroyAllWindows()  # Close all OpenCV windows\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Report the calibration matrix for the camera chosen and verify (using an example) the same. \n",
    "#### 2. Point the camera to a chessboard pattern or any known set of reference points that lie on the same plane. Capture a series of 10 images by changing the orientation of the camera in each iteration. Select any 1 image, and using the image formation pipeline equation, set up the linear equations in matrix form and solve for intrinsic and extrinsic parameters (extrinsic for that particular orientation). You will need to make measurements of the actual 3D world points, and mark pixel coordinates. Once you compute the Rotation matrix, you also need to compute the angles of rotation along each axis. Choose your order of rotation based on your experimentation setup. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing monochrome images from right camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/2685450293.py:19: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/2685450293.py:34: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline, usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from right camera...\n",
      "Image 1 captured from right camera\n",
      "Capturing image 2 from right camera...\n",
      "Image 2 captured from right camera\n",
      "Capturing image 3 from right camera...\n",
      "Image 3 captured from right camera\n",
      "Capturing image 4 from right camera...\n",
      "Image 4 captured from right camera\n",
      "Capturing image 5 from right camera...\n",
      "Image 5 captured from right camera\n",
      "Capturing image 6 from right camera...\n",
      "Image 6 captured from right camera\n",
      "Capturing image 7 from right camera...\n",
      "Image 7 captured from right camera\n",
      "Capturing image 8 from right camera...\n",
      "Image 8 captured from right camera\n",
      "Capturing image 9 from right camera...\n",
      "Image 9 captured from right camera\n",
      "Capturing image 10 from right camera...\n",
      "Image 10 captured from right camera\n",
      "Capturing monochrome images from left camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/2685450293.py:21: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from left camera...\n",
      "Image 1 captured from left camera\n",
      "Capturing image 2 from left camera...\n",
      "Image 2 captured from left camera\n",
      "Capturing image 3 from left camera...\n",
      "Image 3 captured from left camera\n",
      "Capturing image 4 from left camera...\n",
      "Image 4 captured from left camera\n",
      "Capturing image 5 from left camera...\n",
      "Image 5 captured from left camera\n",
      "Capturing image 6 from left camera...\n",
      "Image 6 captured from left camera\n",
      "Capturing image 7 from left camera...\n",
      "Image 7 captured from left camera\n",
      "Capturing image 8 from left camera...\n",
      "Image 8 captured from left camera\n",
      "Capturing image 9 from left camera...\n",
      "Image 9 captured from left camera\n",
      "Capturing image 10 from left camera...\n",
      "Image 10 captured from left camera\n",
      "Capturing color images from rgb camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/2685450293.py:72: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline, usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from RGB camera...\n",
      "Image 1 captured from RGB camera\n",
      "Capturing image 2 from RGB camera...\n",
      "Image 2 captured from RGB camera\n",
      "Capturing image 3 from RGB camera...\n",
      "Image 3 captured from RGB camera\n",
      "Capturing image 4 from RGB camera...\n",
      "Image 4 captured from RGB camera\n",
      "Capturing image 5 from RGB camera...\n",
      "Image 5 captured from RGB camera\n",
      "Capturing image 6 from RGB camera...\n",
      "Image 6 captured from RGB camera\n",
      "Capturing image 7 from RGB camera...\n",
      "Image 7 captured from RGB camera\n",
      "Capturing image 8 from RGB camera...\n",
      "Image 8 captured from RGB camera\n",
      "Capturing image 9 from RGB camera...\n",
      "Image 9 captured from RGB camera\n",
      "Capturing image 10 from RGB camera...\n",
      "Image 10 captured from RGB camera\n",
      "Calibrating cameras...\n",
      "Corners not found for captured_images/right/17120874221513.png\n",
      "Corners not found for captured_images/right/17120874293572.png\n",
      "Corners not found for captured_images/right/17120929353299.png\n",
      "Corners not found for captured_images/right/17120929332715.png\n",
      "Corners not found for captured_images/right/17120929281327.png\n",
      "Corners not found for captured_images/right/17120929301805.png\n",
      "Corners not found for captured_images/right/17120929312110.png\n",
      "Corners not found for captured_images/right/17120929291557.png\n",
      "Corners not found for captured_images/right/17120874303909.png\n",
      "Corners not found for captured_images/right/17120874242142_corners.png\n",
      "Corners not found for captured_images/right/17120874252406.png\n",
      "Corners not found for captured_images/right/17120929373885.png\n",
      "Corners not found for captured_images/right/17120929322389.png\n",
      "Corners not found for captured_images/right/17120874262709.png\n",
      "Corners not found for captured_images/right/17120874273013.png\n",
      "Corners not found for captured_images/right/17120874283309.png\n",
      "Corners not found for captured_images/right/17120874231866.png\n",
      "Corners not found for captured_images/right/17120874211237.png\n",
      "Corners not found for captured_images/right/17120929342987.png\n",
      "Corners not found for captured_images/right/17120929363586.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "Done!!\n",
      "Corners not found for captured_images/left/17120874380037_corners.png\n",
      "Corners not found for captured_images/left/17120874421199.png\n",
      "Corners not found for captured_images/left/17120874369795.png\n",
      "Corners not found for captured_images/left/17120874359520.png\n",
      "Corners not found for captured_images/left/17120874400622.png\n",
      "Corners not found for captured_images/left/17120929439962.png\n",
      "Corners not found for captured_images/left/17120929450254.png\n",
      "Corners not found for captured_images/left/17120929460584.png\n",
      "Corners not found for captured_images/left/17120929470915.png\n",
      "Corners not found for captured_images/left/17120874441793.png\n",
      "Corners not found for captured_images/left/17120929429680.png\n",
      "Corners not found for captured_images/left/17120929481254.png\n",
      "Corners not found for captured_images/left/17120929491536.png\n",
      "Corners not found for captured_images/left/17120929512168.png\n",
      "Corners not found for captured_images/left/17120874452069.png\n",
      "Corners not found for captured_images/left/17120874410892.png\n",
      "Corners not found for captured_images/left/17120929501853.png\n",
      "Corners not found for captured_images/left/17120874390375.png\n",
      "Corners not found for captured_images/left/17120929522424.png\n",
      "Corners not found for captured_images/left/17120874431541.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "Done!!\n",
      "Corners not found for captured_images/rgb/17120878712400.png\n",
      "Corners not found for captured_images/rgb/17120929579039.png\n",
      "Corners not found for captured_images/rgb/17120929645423.png\n",
      "Corners not found for captured_images/rgb/17120929600962.png\n",
      "Corners not found for captured_images/rgb/17120878778959.png\n",
      "Corners not found for captured_images/rgb/17120929589817.png\n",
      "Corners not found for captured_images/rgb/17120878723583_corners.png\n",
      "Corners not found for captured_images/rgb/17120929667578.png\n",
      "Corners not found for captured_images/rgb/17120878745688.png\n",
      "Corners not found for captured_images/rgb/17120878756812.png\n",
      "Corners not found for captured_images/rgb/17120878690087.png\n",
      "Corners not found for captured_images/rgb/17120929678690.png\n",
      "Corners not found for captured_images/rgb/17120878723583_result.png\n",
      "Corners not found for captured_images/rgb/17120878701207.png\n",
      "Corners not found for captured_images/rgb/17120878767948.png\n",
      "Corners not found for captured_images/rgb/17120929612116.png\n",
      "Corners not found for captured_images/rgb/17120929623282.png\n",
      "Corners not found for captured_images/rgb/17120878734627.png\n",
      "Corners not found for captured_images/rgb/17120878679241.png\n",
      "Corners not found for captured_images/rgb/17120929634358.png\n",
      "Corners not found for captured_images/rgb/17120929656520.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from pathlib import Path\n",
    "\n",
    "def capture_monochrome_images(src='right', delay=1000, num_imgs = 10):\n",
    "    if src not in ['right', 'left']: \n",
    "        print(f\"Accepted params are [left, right], but entered src: {src}.\")\n",
    "        return;\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - mono (grayscale) camera\n",
    "    cam = pipeline.createMonoCamera()\n",
    "    if src == 'right':\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    elif src == 'left':\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else:\n",
    "        print(\"Invalid source for monochrome camera\")\n",
    "        return\n",
    "\n",
    "    cam.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "    # Create output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(src)\n",
    "    cam.out.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the grayscale frames from the output defined above\n",
    "        q = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"captured_images/{src}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            print(f\"Capturing image {i+1} from {src} camera...\")\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            cv.imshow(src, frame)\n",
    "\n",
    "            cv.imwrite(f\"captured_images/{src}/{int(time.time() * 10000)}.png\", frame)\n",
    "            print(f\"Image {i+1} captured from {src} camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()            \n",
    "\n",
    "\n",
    "def capture_color_images(delay=1000, num_imgs = 10):\n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - color camera\n",
    "    cam = pipeline.createColorCamera()\n",
    "    cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "    # Create RGB output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(\"rgb\")\n",
    "    cam.video.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the color frames from the output defined above\n",
    "        q = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"captured_images/rgb\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            print(f\"Capturing image {i+1} from RGB camera...\")\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            imS = cv.resize(frame, (960, 540)) # Resize image\n",
    "            cv.imshow(\"rgb\", imS)\n",
    "\n",
    "            cv.imwrite(f\"captured_images/rgb/{int(time.time() * 10000)}.png\", frame)\n",
    "            print(f\"Image {i+1} captured from RGB camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def caliberate_camera(images, src):\n",
    "    if src not in ['right', 'left', 'rgb']: \n",
    "        print(f\"Accepted params are - [left, right, rgb], but entered src: {src}\")\n",
    "        print(\"Enter Correct value for src!!\")\n",
    "        return;\n",
    "\n",
    "    # Termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((6*9, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []  # 3D point in real world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    notFound = []\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Finding chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (9, 6), corners2, ret)\n",
    "            cv.imshow('img', img)\n",
    "\n",
    "            # Saving displayed corners for future references\n",
    "            cv.imwrite(f\"{fname.split('.')[0]}_corners.png\", img)\n",
    "            cv.waitKey(1000)\n",
    "            cv.destroyAllWindows()\n",
    "        else:\n",
    "            # If corners not found, store the file name in the notFound list\n",
    "            notFound.append(fname)\n",
    "            print(f\"Corners not found for {fname}\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # Remove the images whose corners weren't found from the main image list\n",
    "    for i in notFound:\n",
    "        images.remove(i)\n",
    "\n",
    "    # Camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "        # Undistort the image\n",
    "        dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "        # Crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "        # Save the undistorted image\n",
    "        cv.imwrite(f\"{fname.split('.')[0]}_result.png\", dst)\n",
    "\n",
    "    # Save camera matrix and distortion coefficients for future use\n",
    "    print(\"Saving camera matrix...\")\n",
    "    np.savetxt(f\"captured_images/{src}/camera_matrix.txt\", mtx)\n",
    "    print(\"Saving distortion vector...\")\n",
    "    np.savetxt(f\"captured_images/{src}/distortion_vector.txt\", dist)\n",
    "    print(\"Saving rotational vectors...\")\n",
    "    np.savetxt(f\"captured_images/{src}/rotation_vectors.txt\", np.array(rvecs).reshape(-1, 3))\n",
    "    print(\"Saving translation vectors...\")\n",
    "    np.savetxt(f\"captured_images/{src}/translation_vectors.txt\", np.array(tvecs).reshape(-1, 3))\n",
    "    print('Done!!')\n",
    "\n",
    "\n",
    "# Capture images and calibrate cameras\n",
    "print(\"Capturing monochrome images from right camera...\")\n",
    "capture_monochrome_images('right')\n",
    "print(\"Capturing monochrome images from left camera...\")\n",
    "capture_monochrome_images('left')\n",
    "print(\"Capturing color images from rgb camera...\")\n",
    "capture_color_images()\n",
    "\n",
    "# Calibrate cameras\n",
    "print(\"Calibrating cameras...\")\n",
    "caliberate_camera(glob.glob('captured_images/right/*.png'), 'right')\n",
    "caliberate_camera(glob.glob('captured_images/left/*.png'), 'left')\n",
    "caliberate_camera(glob.glob('captured_images/rgb/*.png'), 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Square in mm: 21.92162150557055\n",
      "Calibration Error: 1.921621505570549 mm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_parameters(camera_matrix_file, distortion_vector_file):\n",
    "    camera_params = []\n",
    "    extrinsic_params = []\n",
    "    with open(camera_matrix_file, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_params.append([float(num) for num in line.split(' ')])\n",
    "    with open(distortion_vector_file, 'r') as f:\n",
    "        for line in f:\n",
    "            extrinsic_params.append([float(num) for num in line.split(' ')])\n",
    "    return np.array(camera_params), np.array(extrinsic_params)\n",
    "\n",
    "def correct_distortion(image, camera_params, extrinsic_params):\n",
    "    height, width = image.shape[:2]\n",
    "    new_camera_params, roi = cv2.getOptimalNewCameraMatrix(camera_params, extrinsic_params, (width, height), 1, (width, height))\n",
    "    undistorted = cv2.undistort(image, camera_params, extrinsic_params, None, new_camera_params)\n",
    "    x, y, w, h = roi\n",
    "    undistorted = undistorted[y:y+h, x:x+w]\n",
    "    return undistorted\n",
    "\n",
    "def calculate_error(corners, camera_params, object_distance, known_square_size_mm):\n",
    "    ret, corners = cv2.findChessboardCorners(corners, (9, 6), None)\n",
    "    focal_length_pixels = (camera_params[0, 0] + camera_params[1, 1]) / 2\n",
    "    if ret:\n",
    "        square_size_pixels = np.linalg.norm(corners[3] - corners[4])\n",
    "        square_size_mm = (square_size_pixels / focal_length_pixels) * object_distance \n",
    "        print(f\"Size of Square in mm: {square_size_mm}\")\n",
    "        error = abs(square_size_mm - known_square_size_mm)\n",
    "        return error\n",
    "    return None\n",
    "\n",
    "input_image = cv2.imread('captured_images/right/17120874242142.png')\n",
    "camera_params, extrinsic_params = load_camera_parameters('captured_images/right/camera_matrix.txt', 'captured_images/right/distortion_vector.txt')\n",
    "undistorted_image = correct_distortion(input_image, camera_params, extrinsic_params)\n",
    "gray_image = cv2.cvtColor(undistorted_image, cv2.COLOR_BGR2GRAY)\n",
    "known_square_size_mm = 20  # Set the known size of the chessboard square in mm\n",
    "object_distance = 300  # Set the distance of the object from the camera in mm\n",
    "calibration_error = calculate_error(gray_image, camera_params, object_distance, known_square_size_mm)\n",
    "if calibration_error is not None:\n",
    "    print(f\"Calibration Error: {calibration_error} mm\")\n",
    "else:\n",
    "    print(\"Chessboard corners not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Camera Matrix:\n",
      "[[855.53046232   0.         322.91164513]\n",
      " [  0.         846.05776973 257.14797989]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "Extrinsic Rotation Matrix:\n",
      "[[ 0.91573981  0.11456659  0.38509104]\n",
      " [ 0.09173585  0.87354035 -0.47802907]\n",
      " [-0.39115872  0.47307691  0.7894258 ]] \n",
      "\n",
      "Extrinsic Translation Vector:\n",
      "[[ -99.27374148]\n",
      " [-130.57869143]\n",
      " [ 513.37507446]] \n",
      "\n",
      "Rotation Angles across X, Y, Z axes (degrees):\n",
      "[30.93286966 23.02661748  5.72062055] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def find_chessboard_corners(image):\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray_img, (9, 6), None)\n",
    "    if ret:\n",
    "        refined_corners = cv2.cornerSubPix(gray_img, corners, (11, 11), (-1, -1), \n",
    "                                            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        return refined_corners\n",
    "    return None\n",
    "\n",
    "def extract_image_points(corners):\n",
    "    top_left_corner = corners[0].ravel()\n",
    "    top_right_corner = corners[7].ravel()\n",
    "    bottom_right_corner = corners[-1].ravel()\n",
    "    bottom_left_corner = corners[-8].ravel()\n",
    "    return np.array([top_left_corner, top_right_corner, bottom_right_corner, bottom_left_corner])\n",
    "\n",
    "def solve_pnp(obj_points, img_points, camera_params, extrinsic_params):\n",
    "    ret, rvecs, tvecs = cv2.solvePnP(obj_points, img_points, camera_params, extrinsic_params)\n",
    "    return ret, rvecs, tvecs\n",
    "\n",
    "def rotation_matrix_to_euler_angles(rotation_matrix):\n",
    "    sy = math.sqrt(rotation_matrix[0, 0] * rotation_matrix[0, 0] + rotation_matrix[1, 0] * rotation_matrix[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(rotation_matrix[2, 1], rotation_matrix[2, 2])\n",
    "        y = math.atan2(-rotation_matrix[2, 0], sy)\n",
    "        z = math.atan2(rotation_matrix[1, 0], rotation_matrix[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])\n",
    "        y = math.atan2(-rotation_matrix[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Load the chessboard image\n",
    "chessboard_img = load_image('captured_images/right/17120874242142.png')\n",
    "\n",
    "# Find and refine the chessboard corners\n",
    "corners = find_chessboard_corners(chessboard_img)\n",
    "\n",
    "if corners is not None:\n",
    "    # Draw the corners on the image\n",
    "    cv2.drawChessboardCorners(chessboard_img, (9, 6), corners, True)\n",
    "    cv2.imshow('Corners', chessboard_img)\n",
    "    cv2.waitKey(5)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Extract image points for PnP\n",
    "    img_points = extract_image_points(corners)\n",
    "\n",
    "    # Define 3D real-world points\n",
    "    obj_points = np.array([[0, 0, 0], [216, 0, 0], [216, 162, 0], [0, 162, 0]], dtype='float32')\n",
    "\n",
    "    # Solve PnP\n",
    "    ret, rvecs, tvecs = solve_pnp(obj_points, img_points, camera_params, extrinsic_params)\n",
    "\n",
    "    # Convert rotation vectors to rotation matrix\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rvecs)\n",
    "\n",
    "    # Convert rotation matrix to euler angles\n",
    "    euler_angles = np.degrees(rotation_matrix_to_euler_angles(rotation_matrix))\n",
    "\n",
    "    # Print results\n",
    "    print(\"Intrinsic Camera Matrix:\")\n",
    "    print(camera_params, \"\\n\")\n",
    "    print(\"Extrinsic Rotation Matrix:\")\n",
    "    print(rotation_matrix, \"\\n\")\n",
    "    print(\"Extrinsic Translation Vector:\")\n",
    "    print(tvecs, \"\\n\")\n",
    "    print(\"Rotation Angles across X, Y, Z axes (degrees):\")\n",
    "    print(euler_angles, \"\\n\")\n",
    "else:\n",
    "    print(\"Chessboard corners not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Write a script to find the real world dimensions (e.g. diameter of a ball, side length of a cube) of an object using perspective projection equations. Validate using an experiment where you image an object using your camera from a specific distance (choose any distance but ensure you are able to measure it accurately) between the object and camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_83109/2902555592.py:22: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline, usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from RGB camera...\n",
      "Image 1 captured from RGB camera\n",
      "Capturing image 2 from RGB camera...\n",
      "Image 2 captured from RGB camera\n",
      "Capturing image 3 from RGB camera...\n",
      "Image 3 captured from RGB camera\n",
      "Capturing image 4 from RGB camera...\n",
      "Image 4 captured from RGB camera\n",
      "Capturing image 5 from RGB camera...\n",
      "Image 5 captured from RGB camera\n",
      "Capturing image 6 from RGB camera...\n",
      "Image 6 captured from RGB camera\n",
      "Capturing image 7 from RGB camera...\n",
      "Image 7 captured from RGB camera\n",
      "Capturing image 8 from RGB camera...\n",
      "Image 8 captured from RGB camera\n",
      "Capturing image 9 from RGB camera...\n",
      "Image 9 captured from RGB camera\n",
      "Capturing image 10 from RGB camera...\n",
      "Image 10 captured from RGB camera\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import depthai as dai\n",
    "from pathlib import Path\n",
    "\n",
    "def capture_color_images(delay=1000, num_images=10):\n",
    "    pipeline = dai.Pipeline()\n",
    "    color_cam = pipeline.createColorCamera()\n",
    "    color_cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "    xout_rgb = pipeline.createXLinkOut()\n",
    "    xout_rgb.setStreamName(\"rgb\")\n",
    "    color_cam.video.link(xout_rgb.input)\n",
    "\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "        rgb_queue = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "        Path(f\"captured_images/object/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_images):\n",
    "            print(f\"Capturing image {i+1} from RGB camera...\")\n",
    "            rgb_data = rgb_queue.get()  \n",
    "            rgb_frame = rgb_data.getCvFrame()\n",
    "            resized_frame = cv.resize(rgb_frame, (960, 540))\n",
    "            cv.imshow(\"rgb\", resized_frame)   \n",
    "            cv.imwrite(f\"captured_images/object/circular_object_{i+1}.png\", rgb_frame)\n",
    "            print(f\"Image {i+1} captured from RGB camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "# Capture images using the color camera\n",
    "capture_color_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Intrinsic Matrix:  [[1.10337649e+03 0.00000000e+00 2.24967357e+02]\n",
      " [0.00000000e+00 1.10188906e+03 2.85431664e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "fx: 1103.3764896235605, fy: 1101.8890633756332, Z: 300\n",
      "Center (x, y): 850, 461; Width (w): 415; Height (h): 415\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_circle_properties(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=100, param2=30, minRadius=10, maxRadius=250)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = circles[0, :]\n",
    "        x, y, r = circles[0]\n",
    "        center = (int(x), int(y))\n",
    "        width = int(2 * r)\n",
    "        height = int(2 * r)\n",
    "        return center, width, height\n",
    "    else:\n",
    "        print(\"No circle detected in the image.\")\n",
    "        return None, None, None\n",
    "\n",
    "camera_matrix = np.loadtxt('captured_images/left/camera_matrix.txt')\n",
    "\n",
    "print(\"Camera Intrinsic Matrix: \", camera_matrix)\n",
    "\n",
    "img_path = \"captured_images/object/circular_object_10.png\"\n",
    "object_dist = 300\n",
    "\n",
    "fx, fy = camera_matrix[0, 0], camera_matrix[1, 1]\n",
    "Z = object_dist\n",
    "(x, y), w, h = find_circle_properties(img_path)\n",
    "bbox = (x, y, w, h)\n",
    "\n",
    "print(f\"fx: {fx}, fy: {fy}, Z: {Z}\")\n",
    "print(f\"Center (x, y): {x}, {y}; Width (w): {w}; Height (h): {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real World Co-ordinates: \n",
      "\t 231.10878507752008\n",
      "\t 125.51172762920292\n",
      "\t 343.9442507330152\n",
      "\t 344.40853676993856\n",
      "\n",
      "Diameter of circular object is: 9.7 mm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "def convert_milli_to_inch(x):\n",
    "    return x / 254\n",
    "\n",
    "def calculate_object_distance(image, bbox, fx, fy, Z):\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    Image_point1x = x\n",
    "    Image_point1y = y\n",
    "    Image_point2x = x + w\n",
    "    Image_point2y = y + h\n",
    "\n",
    "    cv2.line(image, (Image_point1x, Image_point1y-h//2), (Image_point1x, Image_point2y-h//2), (0, 0, 255), 8)\n",
    "\n",
    "    Real_point1x = Z * (Image_point1x / fx)\n",
    "    Real_point1y = Z * (Image_point1y / fy)\n",
    "    Real_point2x = Z * (Image_point2x / fx)\n",
    "    Real_point2y = Z * (Image_point2x / fy)\n",
    "\n",
    "    print(\"Real World Co-ordinates: \")\n",
    "    print(\"\\t\", Real_point1x)\n",
    "    print(\"\\t\", Real_point1y)\n",
    "    print(\"\\t\", Real_point2x)\n",
    "    print(\"\\t\", Real_point2y)\n",
    "\n",
    "    dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "\n",
    "    val = round(convert_milli_to_inch(dist) * 10, 2)\n",
    "\n",
    "    cv2.putText(image, str(val) + \" mm\", (Image_point1x - 200, (y + h) // 2 + 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imwrite(\"circilar_object.png\", image)\n",
    "\n",
    "    return val\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "distance = calculate_object_distance(image, bbox, fx, fy, Z)\n",
    "print(\"\\nDiameter of circular object is: {} mm\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
