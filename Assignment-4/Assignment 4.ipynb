{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSc 8830: Computer Vision - Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement an application (must run on web or as an app on mobile device) using the stereo camera where it will recognize, track and estimate dimensions (at least 2D) of any object within 3m distance and inside field-of-view to the camera. You can use barcodes or text recognition tools for identification. However, the entire object must be tracked (not just the barcode or text). Machine/Deep learning tools are NOT allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_79026/191203465.py:138: DeprecationWarning: setConfidenceThreshold() is deprecated, Use 'initialConfig.setConfidenceThreshold()' instead\n",
      "  stereo.setConfidenceThreshold(255)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1844301031A5061300] [0.1.1] [1.015] [MonoCamera(1)] [error] OV7251 only supports THE_480_P/THE_400_P resolutions, defaulting to THE_480_P\n",
      "[1844301031A5061300] [0.1.1] [1.016] [MonoCamera(2)] [error] OV7251 only supports THE_480_P/THE_400_P resolutions, defaulting to THE_480_P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_79026/191203465.py:174: DeprecationWarning: Device(pipeline) starts the pipeline automatically. Use Device() and startPipeline(pipeline) otherwise\n",
      "  device.startPipeline()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def detect_qr(frame):\n",
    "    qcd = cv2.QRCodeDetector()\n",
    "    ret_qr, decoded_info, points, _ = qcd.detectAndDecodeMulti(frame)\n",
    "    if ret_qr:\n",
    "        for s, p in zip(decoded_info, points):\n",
    "            if s:\n",
    "                frame = cv2.polylines(frame, [p.astype(int)], True, (255, 255, 255), 8)\n",
    "                cv2.putText(frame, s, (int(p[0][0]), int(p[0][1])-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                color = (0, 0, 0)\n",
    "                frame = cv2.polylines(frame, [p.astype(int)], True, color, 8)\n",
    "    return frame\n",
    "\n",
    "class ObjTracker:\n",
    "    def __init__(self):\n",
    "        self.obj_centers = {}\n",
    "        self.obj_id_count = 0\n",
    "\n",
    "    def update(self, frame):\n",
    "        roi = frame\n",
    "        obj_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)\n",
    "        mask = obj_detector.apply(roi)\n",
    "        _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        detections = []\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 100:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "        tracked_boxes_ids = self._track_objs(detections)\n",
    "        for box_id in tracked_boxes_ids:\n",
    "            x, y, w, h, obj_id = box_id\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "        return roi\n",
    "\n",
    "    def _track_objs(self, obj_rectangles):\n",
    "        tracked_objects = []\n",
    "        for rect in obj_rectangles:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "            obj_detected = False\n",
    "            for obj_id, center in self.obj_centers.items():\n",
    "                dist = math.hypot(cx - center[0], cy - center[1])\n",
    "                if dist < 25:\n",
    "                    self.obj_centers[obj_id] = (cx, cy)\n",
    "                    tracked_objects.append([x, y, w, h, obj_id])\n",
    "                    obj_detected = True\n",
    "                    break\n",
    "            if not obj_detected:\n",
    "                self.obj_centers[self.obj_id_count] = (cx, cy)\n",
    "                tracked_objects.append([x, y, w, h, self.obj_id_count])\n",
    "                self.obj_id_count += 1\n",
    "\n",
    "        new_obj_centers = {}\n",
    "        for obj_bb_id in tracked_objects:\n",
    "            _, _, _, _, obj_id = obj_bb_id\n",
    "            center = self.obj_centers[obj_id]\n",
    "            new_obj_centers[obj_id] = center\n",
    "\n",
    "        self.obj_centers = new_obj_centers.copy()\n",
    "        return tracked_objects\n",
    "\n",
    "def midpoint(ptA, ptB):\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "class ObjDimensionMarker:\n",
    "    def __init__(self, obj_width_inches):\n",
    "        self.obj_width_inches = obj_width_inches\n",
    "        self.pixelsPerMetric = None\n",
    "\n",
    "    def mark_obj_dims(self, gray_frame):\n",
    "        gray = cv2.GaussianBlur(gray_frame, (7, 7), 0)\n",
    "        edged = cv2.Canny(gray, 50, 100)\n",
    "        edged = cv2.dilate(edged, None, iterations=1)\n",
    "        edged = cv2.erode(edged, None, iterations=1)\n",
    "        cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        cnts = contours.sort_contours(cnts)[0]\n",
    "        result_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        for c in cnts:\n",
    "            if cv2.contourArea(c) < 100:\n",
    "                continue\n",
    "            box = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            box = perspective.order_points(box)\n",
    "            cv2.drawContours(result_frame, [box.astype(\"int\")], -1, (0, 0, 0), 2)\n",
    "\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tltrX, tltrY) = midpoint(tl, tr)\n",
    "            (blbrX, blbrY) = midpoint(bl, br)\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "\n",
    "            cv2.circle(result_frame, (int(tltrX), int(tltrY)), 5, (0, 0, 0), -1)\n",
    "            cv2.circle(result_frame, (int(blbrX), int(blbrY)), 5, (0, 0, 0), -1)\n",
    "            cv2.circle(result_frame, (int(tlblX), int(tlblY)), 5, (0, 0, 0), -1)\n",
    "            cv2.circle(result_frame, (int(trbrX), int(trbrY)), 5, (0, 0, 0), -1)\n",
    "\n",
    "            cv2.line(result_frame, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)), (255, 255, 255), 2)\n",
    "            cv2.line(result_frame, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)), (255, 255, 255), 2)\n",
    "\n",
    "            dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "            dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "\n",
    "            if self.pixelsPerMetric is None:\n",
    "                self.pixelsPerMetric = dB / self.obj_width_inches\n",
    "\n",
    "            dimA_cm = dA / self.pixelsPerMetric * 2.54\n",
    "            dimB_cm = dB / self.pixelsPerMetric * 2.54\n",
    "\n",
    "            cv2.putText(result_frame, \"{:.1f}in\".format(dimA_cm), (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 255, 255), 2)\n",
    "            cv2.putText(result_frame, \"{:.1f}in\".format(dimB_cm), (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255, 255, 255), 2)\n",
    "\n",
    "        return result_frame\n",
    "\n",
    "tracker = ObjTracker()\n",
    "\n",
    "object_marker = ObjDimensionMarker(obj_width_inches=0.995)\n",
    "\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "stereo = pipeline.createStereoDepth()\n",
    "stereo.setConfidenceThreshold(255)\n",
    "\n",
    "left = pipeline.createMonoCamera()\n",
    "left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_720_P)\n",
    "\n",
    "right = pipeline.createMonoCamera()\n",
    "right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_720_P)\n",
    "\n",
    "left.out.link(stereo.left)\n",
    "right.out.link(stereo.right)\n",
    "\n",
    "xoutDepth = pipeline.createXLinkOut()\n",
    "xoutDepth.setStreamName(\"depth\")\n",
    "stereo.depth.link(xoutDepth.input)\n",
    "\n",
    "xoutLeft = pipeline.createXLinkOut()\n",
    "xoutLeft.setStreamName(\"left\")\n",
    "left.out.link(xoutLeft.input)\n",
    "\n",
    "xoutRight = pipeline.createXLinkOut()\n",
    "xoutRight.setStreamName(\"right\")\n",
    "right.out.link(xoutRight.input)\n",
    "\n",
    "cam = pipeline.createColorCamera()\n",
    "cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "xout = pipeline.createXLinkOut()\n",
    "xout.setStreamName(\"rgb\")\n",
    "cam.video.link(xout.input)\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\", maxSize=4, blocking=False)\n",
    "    leftQueue = device.getOutputQueue(name=\"left\", maxSize=4, blocking=False)\n",
    "    rightQueue = device.getOutputQueue(name=\"right\", maxSize=4, blocking=False)\n",
    "    rgbQueue = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "    device.startPipeline()\n",
    "\n",
    "    camera_id = 0\n",
    "    delay = 1\n",
    "\n",
    "    while True:\n",
    "        inDepth = depthQueue.get()\n",
    "        inLeft = leftQueue.get()\n",
    "        inRight = rightQueue.get()\n",
    "        inSrc = rgbQueue.get()\n",
    "\n",
    "        depthFrame = inDepth.getFrame()\n",
    "        leftFrame = inLeft.getCvFrame()\n",
    "        rightFrame = inRight.getCvFrame()\n",
    "        rgbFrame = inSrc.getCvFrame()\n",
    "\n",
    "        stereoFrame = cv2.hconcat([leftFrame, rightFrame])\n",
    "\n",
    "        stereoFrame_with_qr = detect_qr(stereoFrame)\n",
    "\n",
    "        stereoFrame_with_objects_qr = tracker.update(stereoFrame_with_qr)\n",
    "\n",
    "        gray_frame = cv2.cvtColor(rgbFrame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        try:\n",
    "            marked_frame = object_marker.mark_obj_dims(gray_frame)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        cv2.imshow(\"Stereo Vision (Right & Left)\", stereoFrame_with_objects_qr)\n",
    "        cv2.imshow(\"RGB Camera\", marked_frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
